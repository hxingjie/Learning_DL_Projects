# 1.合并
```python
X = torch.arange(12, dtype=torch.float32).reshape(3, 4)
Y = torch.tensor([[2., 1., 4., 3.], [1., 2., 3., 4.], [4., 3., 2., 1]])
print(torch.cat((X, Y), dim=0))  # 第0维合并
print(torch.cat((X, Y), dim=1))  # 第1维合并
```

# 2.通过逻辑运算符获得对应维度的张量
```python
print(X == Y)  
# tensor([[False,  True, False,  True],
#         [False, False, False, False],
#         [False, False, False, False]])
```

# 3.求和
```python
print(X.sum())  # 返回0维的张量，tensor(66.)
```

# 4.广播机制
```python
a = torch.arange(3).reshape(3, 1);
b = torch.arange(2).reshape(1, 2);
print(a + b)  
# 形状不相同的两个张量，此时会将a的第二维复制1次，变成（3，2），b的第一维复制三次，变成（3，2）
# a:[[0, 0]    b:[[0, 1]    a+b:[[0, 1]
#		 [1, 1]       [0, 1]         [1, 2]
#    [2, 2]]      [0, 1]]        [2, 3]]
```

# 5.访问
```python
X = torch.tensor([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9]])

print(X[0]) print(X[-1]) print(X[0:2]) print(X[0:]) print(X[:3])
```

# 6.插入元素
```python
X[0, 0] = 0
X[0:2, :] = 0  # 0到1行的全部列赋值为0
```

# 7.内存
```python
before = id(Y)
Y = X + Y
print(id(Y) == before)  # False, 重新创建了张量赋值给Y

before = id(Y)
Y[:] = X + Y
print(id(Y) == before)  # 对Y的每一个元素重新赋值，没有创建新的张量

before = id(Y)
Y += X
print(id(Y) == before)  # 使Y的每一个元素加上X的对应元素，没有创建新的张量
```

# 8.转换
```python
X = torch.tensor([[1, 2], [3, 4]])
A = X.numpy()
B = torch.tensor(A)
print(type(A), type(B))  # <class 'numpy.ndarray'> <class 'torch.Tensor'>

x = torch.tensor([3.14])
print(x, x.item(), float(x), int(x))
```

# 9.转置
```python
A = torch.arange(20).reshape(5,4)
A.T
```

# 10.对不同维度求和
```python
sum = X.sum(axis=0)
sum = X.sum(axis=1)
sum = X.sum(axis=2)
sum = X.sum(axis=[0,1])
sum = X.sum(axis=[0, 1, 2])
```

# 11.求平均
```python
X.mean()
X.mean(axis=0)
```
