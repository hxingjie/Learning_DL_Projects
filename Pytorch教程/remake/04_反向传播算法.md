```python
import torch

x_data = [1., 2., 3.]
y_data = [2., 4., 6.]

w = torch.Tensor([1.])
w.requires_grad = True  # 计算梯度

def forward(x):
    return x * w  # 

def loss(x, y):
    y_pred = forward(x)
    return (y_pred - y) ** 2
    
if __name__ == '__main__':
    print('before:', 4, forward(4).item())

    for epoch in range(100):
        for x, y in zip(x_data, y_data):
            loss_val = loss(x, y)  # 求损失
            loss_val.backward()  # 反向传播
            print(w.grad.item())
            w.data -= 0.01 * w.grad.data  # 使用损失对w的偏导数（w的梯度）更新w的值
            
            w.grad.data.zero_()  # 梯度清零

    print('after:', 4, forward(4).item())
```
